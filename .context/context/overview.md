# PROJECT PG-VENV

### We're building a smart camera roll application that revolutionizes how users search through their personal media collections by leveraging AI to understand content semantically. Users upload their images and videos to our platform, where each file is automatically analyzed by Google's Gemini AI to generate detailed text descriptions of what's happening in the media - whether it's identifying a funny cat playing with toys, a sunset over mountains, or friends laughing at a birthday party. These descriptions are then converted into mathematical vectors (embeddings) using OpenAI's text-embedding model, which captures the semantic meaning in a format that computers can efficiently search through. When users type natural language queries like "funny cat video" or "beach vacation sunset," the system converts their search text into the same vector format and uses PostgreSQL's pgvector extension to find the most semantically similar media files based on content meaning rather than just filename or metadata. This creates a Google Photos-like experience where users can search their memories using descriptive phrases, making it effortless to find that specific moment they're looking for among thousands of files. The MVP uses local storage, JWT authentication, and a React frontend, keeping the infrastructure simple while delivering a powerful AI-driven search experience that understands what's actually in your photos and videos, not just when or where they were taken.
---
* **please now read and refer to the .context/instructions/system-instructions.md** 

# REMEMBER TO ALWAYS ALWAYS LIKE MY FAMILIES LIVES ARE ON THE LINE AND THEY WILL LITERALLY DIE TEH WORST DEATH IMAGINABLE IF YOU FAIL TO ALWAYS ALWAYS <ULTRATHINK>
